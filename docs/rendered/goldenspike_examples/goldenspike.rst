Goldenspike, an example of an end-to-end analysis using RAIL
============================================================

author: Sam Schmidt, Eric Charles, Alex Malz, John Franklin Crenshaw,
others…

last run successfully: April 28, 2023 (with qp-prob >= 0.8.2)

This notebook demonstrates how to use a the various RAIL Modules to draw
synthetic samples of fluxes by color, apply physical effects to them,
train photo-Z estimators on the samples, test and validate the
preformance of those estimators, and to use the RAIL summarization
modules to obtain n(z) estimates based on the p(z) estimates.

**Creation**

Note that in the parlance of the Creation Module, “degradation” is any
post-processing that occurs to the “true” sample generated by the create
Engine. This can include adding photometric errors, applying quality
cuts, introducing systematic biases, etc.

In this notebook, we will draw both test and training samples from a
RAIL Engine object. Then we will demonstrate how to use RAIL degraders
to apply effects to those samples.

**Training and Estimation**

The RAIL Informer modules “train” or “inform” models used to estimate
p(z) given band fluxes (and potentially other information).

The RAIL Estimation modules then use those same models to actually apply
the model and extract the p(z) estimates.

**p(z) Validation**

The RAIL Validator module applies various metrics.

**p(z) to n(z) Summarization**

The RAIL Summarization modules convert per-galaxy p(z) posteriors to
ensemble n(z) estimates.

Imports
-------

.. code:: ipython3

    # Prerquisites: os, numpy, pathlib, pzflow, tables_io
    import os
    import numpy as np
    from pathlib import Path
    from pzflow.examples import get_galaxy_data
    import tables_io


.. code:: ipython3

    # Various rail modules
    import rail
    from rail.creation.degradation.lsst_error_model import LSSTErrorModel
    from rail.creation.degradation.spectroscopic_degraders import (
        InvRedshiftIncompleteness,
        LineConfusion,
    )
    from rail.creation.degradation.quantityCut import QuantityCut
    from rail.creation.engines.flowEngine import FlowModeler, FlowCreator, FlowPosterior
    from rail.core.data import TableHandle
    from rail.core.stage import RailStage
    from rail.core.utilStages import ColumnMapper, TableConverter
    
    from rail.estimation.algos.bpz_lite import BPZliteInformer, BPZliteEstimator
    from rail.estimation.algos.k_nearneigh import KNearNeighInformer, KNearNeighEstimator
    from rail.estimation.algos.flexzboost import FlexZBoostInformer, FlexZBoostEstimator
    
    from rail.estimation.algos.naive_stack import NaiveStackSummarizer
    from rail.estimation.algos.point_est_hist import PointEstHistSummarizer
    
    from rail.evaluation.evaluator import Evaluator


RAIL now uses ceci as a back-end, which takes care of a lot of file I/O
decisions to be consistent with other choices in DESC.

This bit effectively overrides a ceci default to prevent overwriting
previous results, generally good but not necessary for this demo.

The ``DataStore`` uses ``DataHandle`` objects to keep track of the
connections between the various stages. When one stage returns a
``DataHandle`` and then you pass that ``DataHandle`` to another stage,
the underlying code can establish the connections needed to build a
reproducilble pipeline.

.. code:: ipython3

    DS = RailStage.data_store
    DS.__class__.allow_overwrite = True


Here we need a few configuration parameters to deal with differences in
data schema between existing PZ codes.

.. code:: ipython3

    from rail.core.utils import RAILDIR
    
    flow_file = os.path.join(RAILDIR, "examples/goldenspike/data/pretrained_flow.pkl")
    bands = ["u", "g", "r", "i", "z", "y"]
    band_dict = {band: f"mag_{band}_lsst" for band in bands}
    rename_dict = {f"mag_{band}_lsst_err": f"mag_err_{band}_lsst" for band in bands}


Train the Flow Engine
---------------------

First we need to train the normalizing flow that will serve as the
engine for the notebook.

In the cell below, we load the example galaxy catalog from PZFlow and
save it so that it can be used to train the flow. We also set the path
where we will save the flow.

.. code:: ipython3

    DATA_DIR = Path().resolve() / "data"
    DATA_DIR.mkdir(exist_ok=True)
    
    catalog_file = DATA_DIR / "base_catalog.pq"
    catalog = get_galaxy_data().rename(band_dict, axis=1)
    tables_io.write(catalog, str(catalog_file.with_suffix("")), catalog_file.suffix[1:])
    
    catalog_file = str(catalog_file)
    flow_file = str(DATA_DIR / "trained_flow.pkl")


Now we set the parameters for the FlowModeler, i.e. the pipeline stage
that trains the flow:

.. code:: ipython3

    flow_modeler_params = {
        "name": "flow_modeler",
        "input": catalog_file,
        "model": flow_file,
        "seed": 0,
        "phys_cols": {"redshift": [0, 3]},
        "phot_cols": {
            "mag_u_lsst": [17, 35],
            "mag_g_lsst": [16, 32],
            "mag_r_lsst": [15, 30],
            "mag_i_lsst": [15, 30],
            "mag_z_lsst": [14, 29],
            "mag_y_lsst": [14, 28],
        },
        "calc_colors": {"ref_column_name": "mag_i_lsst"},
    }


Now we will create the flow and train it

.. code:: ipython3

    flow_modeler = FlowModeler.make_stage(**flow_modeler_params)


.. code:: ipython3

    flow_modeler.fit_model()



.. parsed-literal::

    Inserting handle into data store.  input: /home/runner/work/rail_notebooks/rail_notebooks/rail/examples/goldenspike_examples/data/base_catalog.pq, flow_modeler
    Training 30 epochs 
    Loss:
    (0) 21.3266
    (1) 4.1139
    (2) 3.5145
    (3) 1.8794
    (4) -0.1582
    (5) 1.3641
    (6) inf
    Training stopping after epoch 6 because training loss diverged.
    Inserting handle into data store.  model_flow_modeler: /home/runner/work/rail_notebooks/rail_notebooks/rail/examples/goldenspike_examples/data/inprogress_trained_flow.pkl, flow_modeler




.. parsed-literal::

    <rail.tools.flow_handle.FlowHandle at 0x7f9b9b58a290>



Make mock data
--------------

Now we will use the trained flow to create training and test data for
the photo-z estimators.

For both the training and test data we will:

1. Use the Flow to produce some synthetic data
2. Use the LSSTErrorModel to add photometric errors
3. Use the FlowPosterior to estimate the redshift posteriors for the
   degraded sample
4. Use the ColumnMapper to rename the error columns so that they match
   the names in DC2.
5. Use the TableConverter to convert the data to a numpy dictionary,
   which will be stored in a hdf5 file with the same schema as the DC2
   data

Training sample
~~~~~~~~~~~~~~~

For the training data we are going to apply a couple of extra
degradation effects to the data beyond what we do to create test data,
as the training data will have some spectroscopic incompleteness. This
will allow us to see how the trained models perform with imperfect
training data.

More details about the degraders are available in the
``rail/examples/creation_examples/degradation_demo.ipynb`` notebook.

.. code:: ipython3

    flow_creator_train = FlowCreator.make_stage(
        name="flow_creator_train",
        model=flow_modeler.get_handle("model"),
        n_samples=50,
        seed=1235,
    )
    
    lsst_error_model_train = LSSTErrorModel.make_stage(
        name="lsst_error_model_train",
        renameDict=band_dict,
        ndFlag=np.nan,
        seed=29,
    )
    
    inv_redshift = InvRedshiftIncompleteness.make_stage(
        name="inv_redshift",
        pivot_redshift=1.0,
    )
    
    line_confusion = LineConfusion.make_stage(
        name="line_confusion",
        true_wavelen=5007.0,
        wrong_wavelen=3727.0,
        frac_wrong=0.05,
    )
    
    quantity_cut = QuantityCut.make_stage(
        name="quantity_cut",
        cuts={"mag_i_lsst": 25.0},
    )
    
    col_remapper_train = ColumnMapper.make_stage(
        name="col_remapper_train",
        columns=rename_dict,
    )
    
    table_conv_train = TableConverter.make_stage(
        name="table_conv_train",
        output_format="numpyDict",
    )


.. code:: ipython3

    train_data_orig = flow_creator_train.sample(150, 1235)
    train_data_errs = lsst_error_model_train(train_data_orig, seed=66)
    train_data_inc = inv_redshift(train_data_errs)
    train_data_conf = line_confusion(train_data_inc)
    train_data_cut = quantity_cut(train_data_conf)
    train_data_pq = col_remapper_train(train_data_cut)
    train_data = table_conv_train(train_data_pq)



.. parsed-literal::

    Inserting handle into data store.  output_flow_creator_train: inprogress_output_flow_creator_train.pq, flow_creator_train
    Inserting handle into data store.  output_lsst_error_model_train: inprogress_output_lsst_error_model_train.pq, lsst_error_model_train
    Inserting handle into data store.  output_inv_redshift: inprogress_output_inv_redshift.pq, inv_redshift
    Inserting handle into data store.  output_line_confusion: inprogress_output_line_confusion.pq, line_confusion
    Inserting handle into data store.  output_quantity_cut: inprogress_output_quantity_cut.pq, quantity_cut
    Inserting handle into data store.  output_col_remapper_train: inprogress_output_col_remapper_train.pq, col_remapper_train
    Inserting handle into data store.  output_table_conv_train: inprogress_output_table_conv_train.hdf5, table_conv_train


Let’s examine the quantities that we’ve generated, we’ll use the handy
``tables_io`` package to temporarily write to a pandas dataframe for
quick writeout of the columns:

.. code:: ipython3

    train_table = tables_io.convertObj(train_data.data, tables_io.types.PD_DATAFRAME)
    train_table.head()





.. raw:: html

    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }
    
        .dataframe tbody tr th {
            vertical-align: top;
        }
    
        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>redshift</th>
          <th>mag_u_lsst</th>
          <th>mag_err_u_lsst</th>
          <th>mag_g_lsst</th>
          <th>mag_err_g_lsst</th>
          <th>mag_r_lsst</th>
          <th>mag_err_r_lsst</th>
          <th>mag_i_lsst</th>
          <th>mag_err_i_lsst</th>
          <th>mag_z_lsst</th>
          <th>mag_err_z_lsst</th>
          <th>mag_y_lsst</th>
          <th>mag_err_y_lsst</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.776368</td>
          <td>27.096006</td>
          <td>0.461011</td>
          <td>26.555770</td>
          <td>0.104944</td>
          <td>25.347148</td>
          <td>0.035449</td>
          <td>24.179230</td>
          <td>0.018918</td>
          <td>23.598360</td>
          <td>0.019891</td>
          <td>23.441322</td>
          <td>0.038977</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.707868</td>
          <td>26.408446</td>
          <td>0.269012</td>
          <td>26.318758</td>
          <td>0.085249</td>
          <td>25.584306</td>
          <td>0.043736</td>
          <td>24.988744</td>
          <td>0.038232</td>
          <td>24.598414</td>
          <td>0.047699</td>
          <td>24.638287</td>
          <td>0.112221</td>
        </tr>
        <tr>
          <th>2</th>
          <td>1.089314</td>
          <td>25.139119</td>
          <td>0.091495</td>
          <td>24.467253</td>
          <td>0.016957</td>
          <td>23.384858</td>
          <td>0.007806</td>
          <td>22.341993</td>
          <td>0.006124</td>
          <td>8.789131</td>
          <td>0.005000</td>
          <td>6.992166</td>
          <td>0.005000</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.484889</td>
          <td>25.979984</td>
          <td>0.188629</td>
          <td>25.557817</td>
          <td>0.043487</td>
          <td>25.104019</td>
          <td>0.028621</td>
          <td>24.368909</td>
          <td>0.022229</td>
          <td>24.368547</td>
          <td>0.038904</td>
          <td>24.071658</td>
          <td>0.068173</td>
        </tr>
        <tr>
          <th>4</th>
          <td>0.553523</td>
          <td>25.291620</td>
          <td>0.104513</td>
          <td>24.187720</td>
          <td>0.013566</td>
          <td>23.348308</td>
          <td>0.007660</td>
          <td>22.705591</td>
          <td>0.006977</td>
          <td>22.343707</td>
          <td>0.007994</td>
          <td>22.300595</td>
          <td>0.014683</td>
        </tr>
      </tbody>
    </table>
    </div>



You see that we’ve generated redshifts, ugrizy magnitudes, and magnitude
errors with names that match those in the cosmoDC2_v1.1.4_image data.

Testing sample
~~~~~~~~~~~~~~

For the test sample we will:

1. Use the Flow to produce some synthetic data
2. Use the LSSTErrorModel to smear the data
3. Use the FlowPosterior to estimate the redshift posteriors for the
   degraded sample
4. Use ColumnMapper to rename some of the columns to match DC2
5. Use the TableConverter to convert the data to a numpy dictionary,
   which will be stored in a hdf5 file with the same schema as the DC2
   data

.. code:: ipython3

    flow_creator_test = FlowCreator.make_stage(
        name="flow_creator_test",
        model=flow_modeler.get_handle("model"),
        n_samples=50,
    )
    
    lsst_error_model_test = LSSTErrorModel.make_stage(
        name="lsst_error_model_test",
        renameDict=band_dict,
        ndFlag=np.nan,
    )
    
    flow_post_test = FlowPosterior.make_stage(
        name="flow_post_test",
        model=flow_modeler.get_handle("model"),
        column="redshift",
        grid=np.linspace(0.0, 5.0, 21),
    )
    
    col_remapper_test = ColumnMapper.make_stage(
        name="col_remapper_test",
        columns=rename_dict,
        hdf5_groupname="",
    )
    
    table_conv_test = TableConverter.make_stage(
        name="table_conv_test",
        output_format="numpyDict",
    )


.. code:: ipython3

    test_data_orig = flow_creator_test.sample(150, 1234)
    test_data_errs = lsst_error_model_test(test_data_orig, seed=58)
    test_data_post = flow_post_test.get_posterior(test_data_errs, err_samples=None)
    test_data_pq = col_remapper_test(test_data_errs)
    test_data = table_conv_test(test_data_pq)



.. parsed-literal::

    Inserting handle into data store.  output_flow_creator_test: inprogress_output_flow_creator_test.pq, flow_creator_test
    Inserting handle into data store.  output_lsst_error_model_test: inprogress_output_lsst_error_model_test.pq, lsst_error_model_test
    Inserting handle into data store.  output_flow_post_test: inprogress_output_flow_post_test.hdf5, flow_post_test
    Inserting handle into data store.  output_col_remapper_test: inprogress_output_col_remapper_test.pq, col_remapper_test
    Inserting handle into data store.  output_table_conv_test: inprogress_output_table_conv_test.hdf5, table_conv_test


.. parsed-literal::

    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/qp/interp_pdf.py:83: RuntimeWarning: invalid value encountered in divide
      self._ycumul = (self._ycumul.T / self._ycumul[:,-1]).T


.. code:: ipython3

    test_table = tables_io.convertObj(test_data.data, tables_io.types.PD_DATAFRAME)
    test_table.head()





.. raw:: html

    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }
    
        .dataframe tbody tr th {
            vertical-align: top;
        }
    
        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>redshift</th>
          <th>mag_u_lsst</th>
          <th>mag_err_u_lsst</th>
          <th>mag_g_lsst</th>
          <th>mag_err_g_lsst</th>
          <th>mag_r_lsst</th>
          <th>mag_err_r_lsst</th>
          <th>mag_i_lsst</th>
          <th>mag_err_i_lsst</th>
          <th>mag_z_lsst</th>
          <th>mag_err_z_lsst</th>
          <th>mag_y_lsst</th>
          <th>mag_err_y_lsst</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.182804</td>
          <td>26.135859</td>
          <td>0.214929</td>
          <td>24.984569</td>
          <td>0.026282</td>
          <td>24.388399</td>
          <td>0.015583</td>
          <td>24.028153</td>
          <td>0.016684</td>
          <td>23.890909</td>
          <td>0.025570</td>
          <td>23.627875</td>
          <td>0.045987</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.539859</td>
          <td>25.395984</td>
          <td>0.114433</td>
          <td>24.680702</td>
          <td>0.020256</td>
          <td>23.799778</td>
          <td>0.010022</td>
          <td>23.402364</td>
          <td>0.010344</td>
          <td>23.223785</td>
          <td>0.014611</td>
          <td>22.934286</td>
          <td>0.024972</td>
        </tr>
        <tr>
          <th>2</th>
          <td>1.629625</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>27.407328</td>
          <td>0.217518</td>
          <td>26.308056</td>
          <td>0.083064</td>
          <td>25.527529</td>
          <td>0.061668</td>
          <td>24.960131</td>
          <td>0.065749</td>
          <td>24.500825</td>
          <td>0.099516</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.402639</td>
          <td>27.874355</td>
          <td>0.796538</td>
          <td>27.438832</td>
          <td>0.223296</td>
          <td>26.351841</td>
          <td>0.086331</td>
          <td>25.955206</td>
          <td>0.089993</td>
          <td>25.555003</td>
          <td>0.110991</td>
          <td>25.959948</td>
          <td>0.339467</td>
        </tr>
        <tr>
          <th>4</th>
          <td>2.036373</td>
          <td>25.912178</td>
          <td>0.178140</td>
          <td>25.729358</td>
          <td>0.050623</td>
          <td>25.368662</td>
          <td>0.036130</td>
          <td>24.942092</td>
          <td>0.036686</td>
          <td>24.377120</td>
          <td>0.039200</td>
          <td>23.898813</td>
          <td>0.058489</td>
        </tr>
      </tbody>
    </table>
    </div>



“Inform” some estimators
------------------------

More details about the process of “informing” or “training” the models
used by the estimators is available in the
``rail/examples/estimation_examples/RAIL_estimation_demo.ipynb``
notebook.

We use “inform” rather than “train” to generically refer to the
preprocessing of any prior information. For a machine learning
estimator, that prior information is a training set, but it can also be
an SED template library for a template-fitting or hybrid estimator.

.. code:: ipython3

    inform_bpz = BPZliteInformer.make_stage(
        name="inform_bpz",
        model="bpz.pkl",
        hdf5_groupname="",
    )
    
    inform_knn = KNearNeighInformer.make_stage(
        name="inform_knn",
        nondetect_val=np.nan,
        model="knnpz.pkl",
        hdf5_groupname="",
    )
    
    inform_fzboost = FlexZBoostInformer.make_stage(
        name="inform_FZBoost",
        model="fzboost.pkl",
        hdf5_groupname="",
    )


.. code:: ipython3

    train_data_errs.data.keys()




.. parsed-literal::

    Index(['redshift', 'mag_u_lsst', 'mag_u_lsst_err', 'mag_g_lsst',
           'mag_g_lsst_err', 'mag_r_lsst', 'mag_r_lsst_err', 'mag_i_lsst',
           'mag_i_lsst_err', 'mag_z_lsst', 'mag_z_lsst_err', 'mag_y_lsst',
           'mag_y_lsst_err'],
          dtype='object')



.. code:: ipython3

    inform_bpz.inform(train_data)
    inform_knn.inform(train_data)
    inform_fzboost.inform(train_data)



.. parsed-literal::

    using 61 galaxies in calculation
    best values for fo and kt:
    [1.]
    [0.3]
    minimizing for type 0
    best fit z0, alpha, km for type 0: [ 5.30299812e-01  1.72669318e+00 -7.57839184e-04]
    Inserting handle into data store.  model_inform_bpz: inprogress_bpz.pkl, inform_bpz
    split into 46 training and 15 validation samples
    finding best fit sigma and NNeigh...
    
    
    
    best fit values are sigma=0.075 and numneigh=5
    
    
    
    Inserting handle into data store.  model_inform_knn: inprogress_knnpz.pkl, inform_knn
    stacking some data...
    read in training data
    fit the model...


.. parsed-literal::

    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:21:07] WARNING: /workspace/src/learner.cc:742: 
    Parameters: { "silent" } are not used.
    
      warnings.warn(smsg, UserWarning)
    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:21:07] WARNING: /workspace/src/learner.cc:742: 
    Parameters: { "silent" } are not used.
    
      warnings.warn(smsg, UserWarning)
    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:21:08] WARNING: /workspace/src/learner.cc:742: 
    Parameters: { "silent" } are not used.
    
      warnings.warn(smsg, UserWarning)
    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:21:08] WARNING: /workspace/src/learner.cc:742: 
    Parameters: { "silent" } are not used.
    
      warnings.warn(smsg, UserWarning)


.. parsed-literal::

    finding best bump thresh...
    finding best sharpen parameter...
    Retraining with full training set...


.. parsed-literal::

    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:21:13] WARNING: /workspace/src/learner.cc:742: 
    Parameters: { "silent" } are not used.
    
      warnings.warn(smsg, UserWarning)
    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:21:13] WARNING: /workspace/src/learner.cc:742: 
    Parameters: { "silent" } are not used.
    
      warnings.warn(smsg, UserWarning)
    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:21:14] WARNING: /workspace/src/learner.cc:742: 
    Parameters: { "silent" } are not used.
    
      warnings.warn(smsg, UserWarning)
    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:21:14] WARNING: /workspace/src/learner.cc:742: 
    Parameters: { "silent" } are not used.
    
      warnings.warn(smsg, UserWarning)


.. parsed-literal::

    Inserting handle into data store.  model_inform_FZBoost: inprogress_fzboost.pkl, inform_FZBoost




.. parsed-literal::

    <rail.core.data.ModelHandle at 0x7f9b6cd83d60>




Estimate photo-z posteriors
---------------------------

More details about the estimators is available in the
``rail/examples/estimation_examples/RAIL_estimation_demo.ipynb``
notebook.

``RandomGaussEstimator`` is a very simple class that does not actually
predict a meaningful photo-z, instead it produces a randomly drawn
Gaussian for each galaxy. ``trainZEstimator`` is our “pathological”
estimator, it makes a PDF from a histogram of the training data and
assigns that PDF to every galaxy. ``BPZliteEstimator`` is a
template-based code that outputs the posterior estimated given a
specific template set and Bayesian prior. See Benitez (2000) for more
details.

.. code:: ipython3

    estimate_bpz = BPZliteEstimator.make_stage(
        name="estimate_bpz",
        hdf5_groupname="",
        model=inform_bpz.get_handle("model"),
    )
    
    estimate_knn = KNearNeighEstimator.make_stage(
        name="estimate_knn",
        hdf5_groupname="",
        nondetect_val=np.nan,
        model=inform_knn.get_handle("model"),
    )
    
    estimate_fzboost = FlexZBoostEstimator.make_stage(
        name="test_FZBoost",
        nondetect_val=np.nan,
        model=inform_fzboost.get_handle("model"),
        hdf5_groupname="",
        aliases=dict(input="test_data", output="fzboost_estim"),
    )


.. code:: ipython3

    knn_estimated = estimate_knn.estimate(test_data)
    fzboost_estimated = estimate_fzboost.estimate(test_data)
    bpz_estimated = estimate_bpz.estimate(test_data)



.. parsed-literal::

    Process 0 running estimator on chunk 0 - 150
    Process 0 estimating PZ PDF for rows 0 - 150
    Inserting handle into data store.  output_estimate_knn: inprogress_output_estimate_knn.hdf5, estimate_knn
    Process 0 running estimator on chunk 0 - 150
    Process 0 estimating PZ PDF for rows 0 - 150
    Inserting handle into data store.  output_test_FZBoost: inprogress_output_test_FZBoost.hdf5, test_FZBoost
      Generating new AB file El_B2004a.DC2LSST_u.AB....
    El_B2004a DC2LSST_u
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/El_B2004a.DC2LSST_u.AB
      Generating new AB file El_B2004a.DC2LSST_g.AB....
    El_B2004a DC2LSST_g
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/El_B2004a.DC2LSST_g.AB
      Generating new AB file El_B2004a.DC2LSST_r.AB....
    El_B2004a DC2LSST_r
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/El_B2004a.DC2LSST_r.AB
      Generating new AB file El_B2004a.DC2LSST_i.AB....
    El_B2004a DC2LSST_i
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/El_B2004a.DC2LSST_i.AB
      Generating new AB file El_B2004a.DC2LSST_z.AB....
    El_B2004a DC2LSST_z
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/El_B2004a.DC2LSST_z.AB
      Generating new AB file El_B2004a.DC2LSST_y.AB....
    El_B2004a DC2LSST_y
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/El_B2004a.DC2LSST_y.AB
      Generating new AB file Sbc_B2004a.DC2LSST_u.AB....
    Sbc_B2004a DC2LSST_u
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Sbc_B2004a.DC2LSST_u.AB
      Generating new AB file Sbc_B2004a.DC2LSST_g.AB....
    Sbc_B2004a DC2LSST_g
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Sbc_B2004a.DC2LSST_g.AB
      Generating new AB file Sbc_B2004a.DC2LSST_r.AB....
    Sbc_B2004a DC2LSST_r
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Sbc_B2004a.DC2LSST_r.AB
      Generating new AB file Sbc_B2004a.DC2LSST_i.AB....
    Sbc_B2004a DC2LSST_i
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Sbc_B2004a.DC2LSST_i.AB
      Generating new AB file Sbc_B2004a.DC2LSST_z.AB....
    Sbc_B2004a DC2LSST_z
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Sbc_B2004a.DC2LSST_z.AB
      Generating new AB file Sbc_B2004a.DC2LSST_y.AB....
    Sbc_B2004a DC2LSST_y
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Sbc_B2004a.DC2LSST_y.AB
      Generating new AB file Scd_B2004a.DC2LSST_u.AB....
    Scd_B2004a DC2LSST_u
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Scd_B2004a.DC2LSST_u.AB
      Generating new AB file Scd_B2004a.DC2LSST_g.AB....
    Scd_B2004a DC2LSST_g
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Scd_B2004a.DC2LSST_g.AB
      Generating new AB file Scd_B2004a.DC2LSST_r.AB....
    Scd_B2004a DC2LSST_r
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Scd_B2004a.DC2LSST_r.AB
      Generating new AB file Scd_B2004a.DC2LSST_i.AB....
    Scd_B2004a DC2LSST_i
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Scd_B2004a.DC2LSST_i.AB
      Generating new AB file Scd_B2004a.DC2LSST_z.AB....
    Scd_B2004a DC2LSST_z
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Scd_B2004a.DC2LSST_z.AB
      Generating new AB file Scd_B2004a.DC2LSST_y.AB....
    Scd_B2004a DC2LSST_y
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Scd_B2004a.DC2LSST_y.AB
      Generating new AB file Im_B2004a.DC2LSST_u.AB....
    Im_B2004a DC2LSST_u
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Im_B2004a.DC2LSST_u.AB
      Generating new AB file Im_B2004a.DC2LSST_g.AB....
    Im_B2004a DC2LSST_g
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Im_B2004a.DC2LSST_g.AB
      Generating new AB file Im_B2004a.DC2LSST_r.AB....
    Im_B2004a DC2LSST_r
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Im_B2004a.DC2LSST_r.AB
      Generating new AB file Im_B2004a.DC2LSST_i.AB....
    Im_B2004a DC2LSST_i
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Im_B2004a.DC2LSST_i.AB
      Generating new AB file Im_B2004a.DC2LSST_z.AB....
    Im_B2004a DC2LSST_z
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Im_B2004a.DC2LSST_z.AB
      Generating new AB file Im_B2004a.DC2LSST_y.AB....
    Im_B2004a DC2LSST_y
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/Im_B2004a.DC2LSST_y.AB
      Generating new AB file SB3_B2004a.DC2LSST_u.AB....
    SB3_B2004a DC2LSST_u
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB3_B2004a.DC2LSST_u.AB
      Generating new AB file SB3_B2004a.DC2LSST_g.AB....
    SB3_B2004a DC2LSST_g
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB3_B2004a.DC2LSST_g.AB
      Generating new AB file SB3_B2004a.DC2LSST_r.AB....
    SB3_B2004a DC2LSST_r
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB3_B2004a.DC2LSST_r.AB
      Generating new AB file SB3_B2004a.DC2LSST_i.AB....
    SB3_B2004a DC2LSST_i
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB3_B2004a.DC2LSST_i.AB
      Generating new AB file SB3_B2004a.DC2LSST_z.AB....
    SB3_B2004a DC2LSST_z
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB3_B2004a.DC2LSST_z.AB
      Generating new AB file SB3_B2004a.DC2LSST_y.AB....
    SB3_B2004a DC2LSST_y
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB3_B2004a.DC2LSST_y.AB
      Generating new AB file SB2_B2004a.DC2LSST_u.AB....
    SB2_B2004a DC2LSST_u
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB2_B2004a.DC2LSST_u.AB
      Generating new AB file SB2_B2004a.DC2LSST_g.AB....
    SB2_B2004a DC2LSST_g
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB2_B2004a.DC2LSST_g.AB
      Generating new AB file SB2_B2004a.DC2LSST_r.AB....
    SB2_B2004a DC2LSST_r
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB2_B2004a.DC2LSST_r.AB
      Generating new AB file SB2_B2004a.DC2LSST_i.AB....
    SB2_B2004a DC2LSST_i
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB2_B2004a.DC2LSST_i.AB
      Generating new AB file SB2_B2004a.DC2LSST_z.AB....
    SB2_B2004a DC2LSST_z
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB2_B2004a.DC2LSST_z.AB
      Generating new AB file SB2_B2004a.DC2LSST_y.AB....
    SB2_B2004a DC2LSST_y
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/SB2_B2004a.DC2LSST_y.AB
      Generating new AB file ssp_25Myr_z008.DC2LSST_u.AB....
    ssp_25Myr_z008 DC2LSST_u
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_25Myr_z008.DC2LSST_u.AB
      Generating new AB file ssp_25Myr_z008.DC2LSST_g.AB....
    ssp_25Myr_z008 DC2LSST_g
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_25Myr_z008.DC2LSST_g.AB
      Generating new AB file ssp_25Myr_z008.DC2LSST_r.AB....
    ssp_25Myr_z008 DC2LSST_r
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_25Myr_z008.DC2LSST_r.AB
      Generating new AB file ssp_25Myr_z008.DC2LSST_i.AB....
    ssp_25Myr_z008 DC2LSST_i
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_25Myr_z008.DC2LSST_i.AB
      Generating new AB file ssp_25Myr_z008.DC2LSST_z.AB....
    ssp_25Myr_z008 DC2LSST_z
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_25Myr_z008.DC2LSST_z.AB
      Generating new AB file ssp_25Myr_z008.DC2LSST_y.AB....
    ssp_25Myr_z008 DC2LSST_y
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_25Myr_z008.DC2LSST_y.AB
      Generating new AB file ssp_5Myr_z008.DC2LSST_u.AB....
    ssp_5Myr_z008 DC2LSST_u
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_5Myr_z008.DC2LSST_u.AB
      Generating new AB file ssp_5Myr_z008.DC2LSST_g.AB....
    ssp_5Myr_z008 DC2LSST_g
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_5Myr_z008.DC2LSST_g.AB
      Generating new AB file ssp_5Myr_z008.DC2LSST_r.AB....
    ssp_5Myr_z008 DC2LSST_r
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_5Myr_z008.DC2LSST_r.AB
      Generating new AB file ssp_5Myr_z008.DC2LSST_i.AB....
    ssp_5Myr_z008 DC2LSST_i
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_5Myr_z008.DC2LSST_i.AB
      Generating new AB file ssp_5Myr_z008.DC2LSST_z.AB....
    ssp_5Myr_z008 DC2LSST_z
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_5Myr_z008.DC2LSST_z.AB
      Generating new AB file ssp_5Myr_z008.DC2LSST_y.AB....
    ssp_5Myr_z008 DC2LSST_y
    x_res[0] 3000.0
    x_res[-1] 11500.0
    Writing AB file  /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/rail/examples_data/estimation_data/data/AB/ssp_5Myr_z008.DC2LSST_y.AB
    Process 0 running estimator on chunk 0 - 150
    Inserting handle into data store.  output_estimate_bpz: inprogress_output_estimate_bpz.hdf5, estimate_bpz


Evaluate the estimates
----------------------

Now we evaluate metrics on the estimates, separately for each estimator.

Each call to the ``Evaluator.evaluate`` will create a table with the
various performance metrics. We will store all of these tables in a
dictionary, keyed by the name of the estimator.

.. code:: ipython3

    eval_dict = dict(bpz=bpz_estimated, fzboost=fzboost_estimated, knn=knn_estimated)
    truth = test_data_orig
    
    result_dict = {}
    for key, val in eval_dict.items():
        the_eval = Evaluator.make_stage(name=f"{key}_eval", truth=truth)
        result_dict[key] = the_eval.evaluate(val, truth)



.. parsed-literal::

    /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/qp/metrics/array_metrics.py:26: UserWarning: p-value floored: true value smaller than 0.001
      return stats.anderson_ksamp([p_random_variables, q_random_variables], **kwargs)


.. parsed-literal::

    Inserting handle into data store.  output_bpz_eval: inprogress_output_bpz_eval.hdf5, bpz_eval
    Inserting handle into data store.  output_fzboost_eval: inprogress_output_fzboost_eval.hdf5, fzboost_eval


.. parsed-literal::

    WARNING:root:Removed 3 PITs from the sample.


.. parsed-literal::

    Inserting handle into data store.  output_knn_eval: inprogress_output_knn_eval.hdf5, knn_eval


| The Pandas DataFrame output format conveniently makes human-readable
  printouts of the metrics.
| This next cell will convert everything to Pandas.

.. code:: ipython3

    results_tables = {
        key: tables_io.convertObj(val.data, tables_io.types.PD_DATAFRAME)
        for key, val in result_dict.items()
    }


.. code:: ipython3

    results_tables["knn"]





.. raw:: html

    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }
    
        .dataframe tbody tr th {
            vertical-align: top;
        }
    
        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>PIT_AD_stat</th>
          <th>PIT_AD_pval</th>
          <th>PIT_AD_significance_level</th>
          <th>PIT_CvM_stat</th>
          <th>PIT_CvM_pval</th>
          <th>PIT_CvM_significance_level</th>
          <th>PIT_KS_stat</th>
          <th>PIT_KS_pval</th>
          <th>PIT_KS_significance_level</th>
          <th>PIT_OutRate_stat</th>
          <th>PIT_OutRate_pval</th>
          <th>PIT_OutRate_significance_level</th>
          <th>POINT_SimgaIQR</th>
          <th>POINT_Bias</th>
          <th>POINT_OutlierRate</th>
          <th>POINT_SigmaMAD</th>
          <th>CDE_stat</th>
          <th>CDE_pval</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>20.235138</td>
          <td>NaN</td>
          <td>0.001</td>
          <td>5.898328</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>0.362657</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>0.32706</td>
          <td>-0.113542</td>
          <td>0.0</td>
          <td>0.281379</td>
          <td>-0.357366</td>
          <td>NaN</td>
        </tr>
      </tbody>
    </table>
    </div>



.. code:: ipython3

    results_tables["fzboost"]





.. raw:: html

    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }
    
        .dataframe tbody tr th {
            vertical-align: top;
        }
    
        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>PIT_AD_stat</th>
          <th>PIT_AD_pval</th>
          <th>PIT_AD_significance_level</th>
          <th>PIT_CvM_stat</th>
          <th>PIT_CvM_pval</th>
          <th>PIT_CvM_significance_level</th>
          <th>PIT_KS_stat</th>
          <th>PIT_KS_pval</th>
          <th>PIT_KS_significance_level</th>
          <th>PIT_OutRate_stat</th>
          <th>PIT_OutRate_pval</th>
          <th>PIT_OutRate_significance_level</th>
          <th>POINT_SimgaIQR</th>
          <th>POINT_Bias</th>
          <th>POINT_OutlierRate</th>
          <th>POINT_SigmaMAD</th>
          <th>CDE_stat</th>
          <th>CDE_pval</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>8.923188</td>
          <td>NaN</td>
          <td>0.001</td>
          <td>2.217865</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>0.213177</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>0.228792</td>
          <td>-0.055135</td>
          <td>0.0</td>
          <td>0.183056</td>
          <td>-0.611644</td>
          <td>NaN</td>
        </tr>
      </tbody>
    </table>
    </div>



.. code:: ipython3

    results_tables["bpz"]





.. raw:: html

    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }
    
        .dataframe tbody tr th {
            vertical-align: top;
        }
    
        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>PIT_AD_stat</th>
          <th>PIT_AD_pval</th>
          <th>PIT_AD_significance_level</th>
          <th>PIT_CvM_stat</th>
          <th>PIT_CvM_pval</th>
          <th>PIT_CvM_significance_level</th>
          <th>PIT_KS_stat</th>
          <th>PIT_KS_pval</th>
          <th>PIT_KS_significance_level</th>
          <th>PIT_OutRate_stat</th>
          <th>PIT_OutRate_pval</th>
          <th>PIT_OutRate_significance_level</th>
          <th>POINT_SimgaIQR</th>
          <th>POINT_Bias</th>
          <th>POINT_OutlierRate</th>
          <th>POINT_SigmaMAD</th>
          <th>CDE_stat</th>
          <th>CDE_pval</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>14.514278</td>
          <td>NaN</td>
          <td>0.001</td>
          <td>2.996804</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>0.22587</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>NaN</td>
          <td>0.147649</td>
          <td>-0.047307</td>
          <td>0.146667</td>
          <td>0.149275</td>
          <td>12.021751</td>
          <td>NaN</td>
        </tr>
      </tbody>
    </table>
    </div>



Summarize the per-galaxy redshift constraints to make population-level distributions
------------------------------------------------------------------------------------

{introduce the summarizers}

First we make the stages, then execute them, then plot the output.

.. code:: ipython3

    point_estimate_test = PointEstHistSummarizer.make_stage(name="point_estimate_test")
    naive_stack_test = NaiveStackSummarizer.make_stage(name="naive_stack_test")


.. code:: ipython3

    point_estimate_ens = point_estimate_test.summarize(eval_dict["bpz"])
    naive_stack_ens = naive_stack_test.summarize(eval_dict["bpz"])



.. parsed-literal::

    Inserting handle into data store.  output_point_estimate_test: inprogress_output_point_estimate_test.hdf5, point_estimate_test
    Inserting handle into data store.  single_NZ_point_estimate_test: inprogress_single_NZ_point_estimate_test.hdf5, point_estimate_test
    Inserting handle into data store.  output_naive_stack_test: inprogress_output_naive_stack_test.hdf5, naive_stack_test
    Inserting handle into data store.  single_NZ_naive_stack_test: inprogress_single_NZ_naive_stack_test.hdf5, naive_stack_test


.. code:: ipython3

    _ = naive_stack_ens.data.plot_native(xlim=(0, 3))




.. image:: ../../../docs/rendered/goldenspike_examples/goldenspike_files/../../../docs/rendered/goldenspike_examples/goldenspike_44_0.png


.. code:: ipython3

    _ = point_estimate_ens.data.plot_native(xlim=(0, 3))




.. image:: ../../../docs/rendered/goldenspike_examples/goldenspike_files/../../../docs/rendered/goldenspike_examples/goldenspike_45_0.png


Convert this to a ``ceci`` Pipeline
-----------------------------------

Now that we have all these stages defined and configured, and that we
have established the connections between them by passing ``DataHandle``
objects between them, we can build a ``ceci`` Pipeline.

.. code:: ipython3

    import ceci
    
    pipe = ceci.Pipeline.interactive()
    stages = [
        # train the flow
        flow_modeler,
        # create the training catalog
        flow_creator_train,
        lsst_error_model_train,
        inv_redshift,
        line_confusion,
        quantity_cut,
        col_remapper_train,
        table_conv_train,
        # create the test catalog
        flow_creator_test,
        lsst_error_model_test,
        col_remapper_test,
        table_conv_test,
        # inform the estimators
        inform_bpz,
        inform_knn,
        inform_fzboost,
        # estimate posteriors
        estimate_bpz,
        estimate_knn,
        estimate_fzboost,
        # estimate n(z), aka "summarize"
        point_estimate_test,
        naive_stack_test,
    ]
    for stage in stages:
        pipe.add_stage(stage)


.. code:: ipython3

    pipe.initialize(
        dict(input=catalog_file), dict(output_dir=".", log_dir=".", resume=False), None
    )





.. parsed-literal::

    (({'flow_modeler': <Job flow_modeler>,
       'flow_creator_test': <Job flow_creator_test>,
       'lsst_error_model_test': <Job lsst_error_model_test>,
       'col_remapper_test': <Job col_remapper_test>,
       'table_conv_test': <Job table_conv_test>,
       'flow_creator_train': <Job flow_creator_train>,
       'lsst_error_model_train': <Job lsst_error_model_train>,
       'inv_redshift': <Job inv_redshift>,
       'line_confusion': <Job line_confusion>,
       'quantity_cut': <Job quantity_cut>,
       'col_remapper_train': <Job col_remapper_train>,
       'table_conv_train': <Job table_conv_train>,
       'inform_FZBoost': <Job inform_FZBoost>,
       'test_FZBoost': <Job test_FZBoost>,
       'inform_knn': <Job inform_knn>,
       'estimate_knn': <Job estimate_knn>,
       'inform_bpz': <Job inform_bpz>,
       'estimate_bpz': <Job estimate_bpz>,
       'naive_stack_test': <Job naive_stack_test>,
       'point_estimate_test': <Job point_estimate_test>},
      [<rail.creation.engines.flowEngine.FlowModeler at 0x7f9b9b50be80>,
       <rail.creation.engines.flowEngine.FlowCreator at 0x7f9ba044e080>,
       <rail.creation.degradation.lsst_error_model.LSSTErrorModel at 0x7f9b6f376e60>,
       Stage that applies remaps the following column names in a pandas DataFrame:
       f{str(self.config.columns)},
       <rail.core.utilStages.TableConverter at 0x7f9b6faf8fd0>,
       <rail.creation.engines.flowEngine.FlowCreator at 0x7f9b6f4d8ac0>,
       <rail.creation.degradation.lsst_error_model.LSSTErrorModel at 0x7f9b6f4d9270>,
       <rail.creation.degradation.spectroscopic_degraders.InvRedshiftIncompleteness at 0x7f9b6f4d83a0>,
       <rail.creation.degradation.spectroscopic_degraders.LineConfusion at 0x7f9b6f4d8610>,
       Degrader that applies the following cuts to a pandas DataFrame:
       {column: (min, max), ...}
       {'mag_i_lsst': (-inf, 25.0)},
       Stage that applies remaps the following column names in a pandas DataFrame:
       f{str(self.config.columns)},
       <rail.core.utilStages.TableConverter at 0x7f9b6f375f30>,
       <rail.estimation.algos.flexzboost.FlexZBoostInformer at 0x7f9b6ec768c0>,
       <rail.estimation.algos.flexzboost.FlexZBoostEstimator at 0x7f9b6fa87c40>,
       <rail.estimation.algos.k_nearneigh.KNearNeighInformer at 0x7f9b6fa872e0>,
       <rail.estimation.algos.k_nearneigh.KNearNeighEstimator at 0x7f9b6c64e020>,
       <rail.estimation.algos.bpz_lite.BPZliteInformer at 0x7f9b6faf92d0>,
       <rail.estimation.algos.bpz_lite.BPZliteEstimator at 0x7f9b6faf9240>,
       <rail.estimation.algos.naive_stack.NaiveStackSummarizer at 0x7f9b6c6b95d0>,
       <rail.estimation.algos.point_est_hist.PointEstHistSummarizer at 0x7f9b6c6bb940>]),
     {'output_dir': '.', 'log_dir': '.', 'resume': False})



.. code:: ipython3

    pipe.save("tmp_goldenspike.yml")


Read back the pipeline and run it
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code:: ipython3

    pr = ceci.Pipeline.read("tmp_goldenspike.yml")


.. code:: ipython3

    pr.run()



.. parsed-literal::

    
    Executing flow_modeler
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowModeler   --input=/home/runner/work/rail_notebooks/rail_notebooks/rail/examples/goldenspike_examples/data/base_catalog.pq   --name=flow_modeler   --config=tmp_goldenspike_config.yml   --model=.//home/runner/work/rail_notebooks/rail_notebooks/rail/examples/goldenspike_examples/data/trained_flow.pkl 
    Output writing to ./flow_modeler.out
    
    Job flow_modeler has completed successfully!
    
    Executing flow_creator_test
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=.//home/runner/work/rail_notebooks/rail_notebooks/rail/examples/goldenspike_examples/data/trained_flow.pkl   --name=flow_creator_test   --config=tmp_goldenspike_config.yml   --output=./output_flow_creator_test.pq 
    Output writing to ./flow_creator_test.out
    
    Job flow_creator_test has completed successfully!
    
    Executing lsst_error_model_test
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_flow_creator_test.pq   --name=lsst_error_model_test   --config=tmp_goldenspike_config.yml   --output=./output_lsst_error_model_test.pq 
    Output writing to ./lsst_error_model_test.out
    
    Job lsst_error_model_test has completed successfully!
    
    Executing col_remapper_test
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.ColumnMapper   --input=./output_lsst_error_model_test.pq   --name=col_remapper_test   --config=tmp_goldenspike_config.yml   --output=./output_col_remapper_test.pq 
    Output writing to ./col_remapper_test.out
    
    Job col_remapper_test has completed successfully!
    
    Executing table_conv_test
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.TableConverter   --input=./output_col_remapper_test.pq   --name=table_conv_test   --config=tmp_goldenspike_config.yml   --output=./output_table_conv_test.hdf5 
    Output writing to ./table_conv_test.out
    
    Job table_conv_test has completed successfully!
    
    Executing flow_creator_train
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=.//home/runner/work/rail_notebooks/rail_notebooks/rail/examples/goldenspike_examples/data/trained_flow.pkl   --name=flow_creator_train   --config=tmp_goldenspike_config.yml   --output=./output_flow_creator_train.pq 
    Output writing to ./flow_creator_train.out
    
    Job flow_creator_train has completed successfully!
    
    Executing lsst_error_model_train
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_flow_creator_train.pq   --name=lsst_error_model_train   --config=tmp_goldenspike_config.yml   --output=./output_lsst_error_model_train.pq 
    Output writing to ./lsst_error_model_train.out
    
    Job lsst_error_model_train has completed successfully!
    
    Executing inv_redshift
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_degraders.InvRedshiftIncompleteness   --input=./output_lsst_error_model_train.pq   --name=inv_redshift   --config=tmp_goldenspike_config.yml   --output=./output_inv_redshift.pq 
    Output writing to ./inv_redshift.out
    
    Job inv_redshift has completed successfully!
    
    Executing line_confusion
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_degraders.LineConfusion   --input=./output_inv_redshift.pq   --name=line_confusion   --config=tmp_goldenspike_config.yml   --output=./output_line_confusion.pq 
    Output writing to ./line_confusion.out
    
    Job line_confusion has completed successfully!
    
    Executing quantity_cut
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.quantityCut.QuantityCut   --input=./output_line_confusion.pq   --name=quantity_cut   --config=tmp_goldenspike_config.yml   --output=./output_quantity_cut.pq 
    Output writing to ./quantity_cut.out
    
    Job quantity_cut has completed successfully!
    
    Executing col_remapper_train
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.ColumnMapper   --input=./output_quantity_cut.pq   --name=col_remapper_train   --config=tmp_goldenspike_config.yml   --output=./output_col_remapper_train.pq 
    Output writing to ./col_remapper_train.out
    
    Job col_remapper_train has completed successfully!
    
    Executing table_conv_train
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.TableConverter   --input=./output_col_remapper_train.pq   --name=table_conv_train   --config=tmp_goldenspike_config.yml   --output=./output_table_conv_train.hdf5 
    Output writing to ./table_conv_train.out
    
    Job table_conv_train has completed successfully!
    
    Executing inform_FZBoost
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.flexzboost.FlexZBoostInformer   --input=./output_table_conv_train.hdf5   --name=inform_FZBoost   --config=tmp_goldenspike_config.yml   --model=./fzboost.pkl 
    Output writing to ./inform_FZBoost.out
    
    Job inform_FZBoost has completed successfully!
    
    Executing test_FZBoost
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.flexzboost.FlexZBoostEstimator   --model=./fzboost.pkl   --input=./output_table_conv_test.hdf5   --name=test_FZBoost   --config=tmp_goldenspike_config.yml   --output=./output_test_FZBoost.hdf5 
    Output writing to ./test_FZBoost.out
    
    Job test_FZBoost has completed successfully!
    
    Executing inform_knn
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.k_nearneigh.KNearNeighInformer   --input=./output_table_conv_train.hdf5   --name=inform_knn   --config=tmp_goldenspike_config.yml   --model=./knnpz.pkl 
    Output writing to ./inform_knn.out
    
    Job inform_knn has completed successfully!
    
    Executing estimate_knn
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.k_nearneigh.KNearNeighEstimator   --model=./knnpz.pkl   --input=./output_table_conv_test.hdf5   --name=estimate_knn   --config=tmp_goldenspike_config.yml   --output=./output_estimate_knn.hdf5 
    Output writing to ./estimate_knn.out
    
    Job estimate_knn has completed successfully!
    
    Executing inform_bpz
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.bpz_lite.BPZliteInformer   --input=./output_table_conv_train.hdf5   --name=inform_bpz   --config=tmp_goldenspike_config.yml   --model=./bpz.pkl 
    Output writing to ./inform_bpz.out
    
    Job inform_bpz has completed successfully!
    
    Executing estimate_bpz
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.bpz_lite.BPZliteEstimator   --model=./bpz.pkl   --input=./output_table_conv_test.hdf5   --name=estimate_bpz   --config=tmp_goldenspike_config.yml   --output=./output_estimate_bpz.hdf5 
    Output writing to ./estimate_bpz.out
    
    Job estimate_bpz has completed successfully!
    
    Executing naive_stack_test
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.naive_stack.NaiveStackSummarizer   --input=./output_estimate_bpz.hdf5   --name=naive_stack_test   --config=tmp_goldenspike_config.yml   --output=./output_naive_stack_test.hdf5   --single_NZ=./single_NZ_naive_stack_test.hdf5 
    Output writing to ./naive_stack_test.out
    
    Job naive_stack_test has completed successfully!
    
    Executing point_estimate_test
    Command is:
    OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.point_est_hist.PointEstHistSummarizer   --input=./output_estimate_bpz.hdf5   --name=point_estimate_test   --config=tmp_goldenspike_config.yml   --output=./output_point_estimate_test.hdf5   --single_NZ=./single_NZ_point_estimate_test.hdf5 
    Output writing to ./point_estimate_test.out
    
    Job point_estimate_test has completed successfully!




.. parsed-literal::

    0



Clean up:
=========

Finally, you’ll notice that we’ve written a large number of temporary
files in the course of running this demo, to delete these and clean up
the directory just run the ``cleanup.sh`` script in this directory to
delete the data files.

.. code:: ipython3

    # TODO fix and add clean up scripts


