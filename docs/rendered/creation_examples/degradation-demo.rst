Using Engines and Degraders to Generate Galaxy Samples with Errors and Biases
=============================================================================

author: John Franklin Crenshaw, Sam Schmidt, Eric Charles, others…

last run successfully: August 2, 2023

This notebook demonstrates how to use a RAIL Engines to create galaxy
samples, and how to use Degraders to add various errors and biases to
the sample.

Note that in the parlance of the Creation Module, “degradation” is any
post-processing that occurs to the “true” sample generated by the
Engine. This can include adding photometric errors, applying quality
cuts, introducing systematic biases, etc.

In this notebook, we will first learn how to draw samples from a RAIL
Engine object. Then we will demonstrate how to use the following RAIL
Degraders:

1. **LSSTErrorModel**, which adds photometric errors

2. **QuantityCut**, which applies cuts to the specified columns of the
   sample

3. **InvRedshiftIncompleteness**, which introduces sample incompleteness

4. **LineConfusion**, which introduces spectroscopic errors

Throughout the notebook, we will show how you can chain all these
Degraders together to build a more complicated degrader. Hopefully, this
will allow you to see how you can build your own degrader.

*Note on generating redshift posteriors*: regardless of what Degraders
you apply, when you use a Creator to estimate posteriors, the posteriors
will *always* be calculated with respect to the “true” distribution.
This is the whole point of the Creation Module – you can generate
degraded samples for which we still have access to the *true*
posteriors. For an example of how to calculate posteriors, see
``posterior-demo.ipynb``.

.. code:: ipython3

    import matplotlib.pyplot as plt
    from pzflow.examples import get_example_flow
    from rail.creation.engines.flowEngine import FlowCreator
    from rail.creation.degradation.spectroscopic_degraders import (
        InvRedshiftIncompleteness,
        LineConfusion,
    )
    from rail.creation.degradation.lsst_error_model import LSSTErrorModel
    from rail.creation.degradation.quantityCut import QuantityCut
    from rail.core.stage import RailStage


Specify the path to the pretrained ‘pzflow’ used to generate samples
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code:: ipython3

    import pzflow
    import os
    
    flow_file = os.path.join(
        os.path.dirname(pzflow.__file__), "example_files", "example-flow.pzflow.pkl"
    )


We’ll start by setting up the Rail data store. RAIL uses
`ceci <https://github.com/LSSTDESC/ceci>`__, which is designed for
pipelines rather than interactive notebooks, the data store will work
around that and enable us to use data interactively. See the
``rail/examples/goldenspike/goldenspike.ipynb`` example notebook for
more details on the Data Store.

.. code:: ipython3

    DS = RailStage.data_store
    DS.__class__.allow_overwrite = True


“True” Engine
-------------

First, let’s make an Engine that has no degradation. We can use it to
generate a “true” sample, to which we can compare all the degraded
samples below.

Note: in this example, we will use a normalizing flow engine from the
`pzflow <https://github.com/jfcrenshaw/pzflow>`__ package. However,
everything in this notebook is totally agnostic to what the underlying
engine is.

The Engine is a type of RailStage object, so we can make one using the
``RailStage.make_stage`` function for the class of Engine that we want.
We then pass in the configuration parameters as arguments to
``make_stage``.

.. code:: ipython3

    n_samples = int(1e5)
    flowCreator_truth = FlowCreator.make_stage(
        name="truth", model=flow_file, n_samples=n_samples
    )



.. parsed-literal::

    No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)


.. parsed-literal::

    Inserting handle into data store.  model: /opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/pzflow/example_files/example-flow.pzflow.pkl, truth


Let’s check that the Engine correctly read the underlying PZ Flow object
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code:: ipython3

    flowCreator_truth.get_data("model")





.. parsed-literal::

    <pzflow.flow.Flow at 0x7f9e326c9bd0>



Now we invoke the ``sample`` method to generate some samples
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Note that this will return a ``DataHandle`` object, which can keep both
the data itself, and also the path to where the data is written. When
talking to rail stages we can use this as though it were the underlying
data and pass it as an argument. This allows the rail stages to keep
track of where their inputs are coming from.

.. code:: ipython3

    samples_truth = flowCreator_truth.sample(n_samples, seed=0)
    print(samples_truth())
    print("Data was written to ", samples_truth.path)



.. parsed-literal::

    Inserting handle into data store.  output_truth: inprogress_output_truth.pq, truth
           redshift          u          g          r          i          z  \
    0      0.890625  27.370831  26.712662  26.025223  25.327188  25.016500   
    1      1.978239  29.557049  28.361185  27.587231  27.238544  26.628109   
    2      0.974287  26.566015  25.937716  24.787413  23.872456  23.139563   
    3      1.317979  29.042730  28.274593  27.501106  26.648790  26.091450   
    4      1.386366  26.292624  25.774778  25.429958  24.806530  24.367950   
    ...         ...        ...        ...        ...        ...        ...   
    99995  2.147172  26.550978  26.349937  26.135286  26.082020  25.911032   
    99996  1.457508  27.362207  27.036276  26.823139  26.420132  26.110037   
    99997  1.372992  27.736044  27.271955  26.887581  26.416138  26.043434   
    99998  0.855022  28.044552  27.327116  26.599014  25.862331  25.592169   
    99999  1.723768  27.049067  26.526745  26.094595  25.642971  25.197956   
    
                   y  
    0      24.926821  
    1      26.248560  
    2      22.832047  
    3      25.346500  
    4      23.700010  
    ...          ...  
    99995  25.558136  
    99996  25.524904  
    99997  25.456165  
    99998  25.506388  
    99999  24.900501  
    
    [100000 rows x 7 columns]
    Data was written to  output_truth.pq


Degrader 1: LSSTErrorModel
--------------------------

Now, we will demonstrate the ``LSSTErrorModel``, which adds photometric
errors using a model similar to the model from `Ivezic et
al. 2019 <https://arxiv.org/abs/0805.2366>`__ (specifically, it uses the
model from this paper, without making the high SNR assumption. To
restore this assumption and therefore use the exact model from the
paper, set ``highSNR=True``.)

Let’s create an error model with the default settings:

.. code:: ipython3

    errorModel = LSSTErrorModel.make_stage(name="error_model")


To see the details of the model, including the default settings we are
using, you can just print the model:

.. code:: ipython3

    errorModel





.. parsed-literal::

    <rail.creation.degradation.lsst_error_model.LSSTErrorModel at 0x7f9e32777a00>



Now let’s add this error model as a degrader and draw some samples with
photometric errors.

.. code:: ipython3

    samples_w_errs = errorModel(samples_truth)
    samples_w_errs()



.. parsed-literal::

    Inserting handle into data store.  output_error_model: inprogress_output_error_model.pq, error_model




.. raw:: html

    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }
    
        .dataframe tbody tr th {
            vertical-align: top;
        }
    
        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>redshift</th>
          <th>u</th>
          <th>u_err</th>
          <th>g</th>
          <th>g_err</th>
          <th>r</th>
          <th>r_err</th>
          <th>i</th>
          <th>i_err</th>
          <th>z</th>
          <th>z_err</th>
          <th>y</th>
          <th>y_err</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.890625</td>
          <td>31.172297</td>
          <td>3.430576</td>
          <td>26.562721</td>
          <td>0.105583</td>
          <td>26.084861</td>
          <td>0.068194</td>
          <td>25.340978</td>
          <td>0.052257</td>
          <td>25.021891</td>
          <td>0.069445</td>
          <td>25.047443</td>
          <td>0.159796</td>
        </tr>
        <tr>
          <th>1</th>
          <td>1.978239</td>
          <td>inf</td>
          <td>inf</td>
          <td>28.038419</td>
          <td>0.362520</td>
          <td>27.490723</td>
          <td>0.229680</td>
          <td>28.102581</td>
          <td>0.525461</td>
          <td>26.066428</td>
          <td>0.172483</td>
          <td>25.834954</td>
          <td>0.307316</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.974287</td>
          <td>26.873697</td>
          <td>0.389236</td>
          <td>25.882633</td>
          <td>0.057988</td>
          <td>24.797720</td>
          <td>0.021944</td>
          <td>23.873355</td>
          <td>0.014716</td>
          <td>23.128763</td>
          <td>0.013557</td>
          <td>22.861474</td>
          <td>0.023448</td>
        </tr>
        <tr>
          <th>3</th>
          <td>1.317979</td>
          <td>27.914048</td>
          <td>0.817339</td>
          <td>27.705399</td>
          <td>0.277971</td>
          <td>27.204204</td>
          <td>0.180633</td>
          <td>26.703293</td>
          <td>0.172092</td>
          <td>25.931166</td>
          <td>0.153677</td>
          <td>25.795159</td>
          <td>0.297649</td>
        </tr>
        <tr>
          <th>4</th>
          <td>1.386366</td>
          <td>26.336934</td>
          <td>0.253759</td>
          <td>25.750773</td>
          <td>0.051593</td>
          <td>25.483414</td>
          <td>0.039993</td>
          <td>24.809233</td>
          <td>0.032626</td>
          <td>24.301733</td>
          <td>0.036670</td>
          <td>23.576059</td>
          <td>0.043921</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>99995</th>
          <td>2.147172</td>
          <td>26.643909</td>
          <td>0.325091</td>
          <td>26.212954</td>
          <td>0.077661</td>
          <td>26.220695</td>
          <td>0.076900</td>
          <td>26.027656</td>
          <td>0.095907</td>
          <td>26.102146</td>
          <td>0.177794</td>
          <td>25.635739</td>
          <td>0.261534</td>
        </tr>
        <tr>
          <th>99996</th>
          <td>1.457508</td>
          <td>26.621966</td>
          <td>0.319467</td>
          <td>26.982388</td>
          <td>0.151845</td>
          <td>26.542811</td>
          <td>0.102093</td>
          <td>26.446734</td>
          <td>0.138137</td>
          <td>25.959232</td>
          <td>0.157414</td>
          <td>25.461991</td>
          <td>0.226646</td>
        </tr>
        <tr>
          <th>99997</th>
          <td>1.372992</td>
          <td>26.679523</td>
          <td>0.334399</td>
          <td>27.416936</td>
          <td>0.219265</td>
          <td>27.042587</td>
          <td>0.157411</td>
          <td>26.480484</td>
          <td>0.142215</td>
          <td>26.165722</td>
          <td>0.187622</td>
          <td>24.902178</td>
          <td>0.141068</td>
        </tr>
        <tr>
          <th>99998</th>
          <td>0.855022</td>
          <td>26.886674</td>
          <td>0.393155</td>
          <td>27.355825</td>
          <td>0.208363</td>
          <td>26.494891</td>
          <td>0.097896</td>
          <td>25.783669</td>
          <td>0.077364</td>
          <td>25.514723</td>
          <td>0.107157</td>
          <td>25.333237</td>
          <td>0.203557</td>
        </tr>
        <tr>
          <th>99999</th>
          <td>1.723768</td>
          <td>27.557109</td>
          <td>0.643300</td>
          <td>26.442709</td>
          <td>0.095055</td>
          <td>26.216528</td>
          <td>0.076618</td>
          <td>25.710465</td>
          <td>0.072517</td>
          <td>25.169914</td>
          <td>0.079153</td>
          <td>24.799610</td>
          <td>0.129108</td>
        </tr>
      </tbody>
    </table>
    <p>100000 rows × 13 columns</p>
    </div>



Notice some of the magnitudes are inf’s. These are non-detections. This
means those observed fluxes were negative. You can change the limit for
non-detections by setting ``sigLim=...``, where the value you set is the
minimum SNR. Setting ``ndFlag=...`` changes the value used to flag
non-detections.

Let’s plot the error as a function of magnitude

.. code:: ipython3

    fig, ax = plt.subplots(figsize=(5, 4), dpi=100)
    
    for band in "ugrizy":
        # pull out the magnitudes and errors
        mags = samples_w_errs.data[band].to_numpy()
        errs = samples_w_errs.data[band + "_err"].to_numpy()
    
        # sort them by magnitude
        mags, errs = mags[mags.argsort()], errs[mags.argsort()]
    
        # plot errs vs mags
        ax.plot(mags, errs, label=band)
    
    ax.legend()
    ax.set(xlabel="Magnitude (AB)", ylabel="Error (mags)")
    plt.show()




.. image:: ../../../docs/rendered/creation_examples/degradation-demo_files/../../../docs/rendered/creation_examples/degradation-demo_19_0.png


You can see that the photometric error increases as magnitude gets
dimmer, just like you would expect. Notice, however, that we have
galaxies as dim as magnitude 30. This is because the Flow produces a
sample much deeper than the LSST 5-sigma limiting magnitudes. There are
no galaxies dimmer than magnitude 30 because LSSTErrorModel sets
magnitudes > 30 equal to NaN (the default flag for non-detections).

Degrader 2: QuantityCut
-----------------------

Recall how the sample above has galaxies as dim as magnitude 30. This is
well beyond the LSST 5-sigma limiting magnitudes, so it will be useful
to apply cuts to the data to filter out these super-dim samples. We can
apply these cuts using the ``QuantityCut`` degrader. This degrader will
cut out any samples that do not pass all of the specified cuts.

Let’s make and run degraders that first adds photometric errors, then
cuts at i<25.3, which is the LSST gold sample.

.. code:: ipython3

    gold_cut = QuantityCut.make_stage(name="cuts", cuts={"i": 25.3})


Now we can stick this into a Creator and draw a new sample

.. code:: ipython3

    samples_gold_w_errs = gold_cut(samples_w_errs)



.. parsed-literal::

    Inserting handle into data store.  output_cuts: inprogress_output_cuts.pq, cuts


If you look at the i column, you will see there are no longer any
samples with i > 25.3. The number of galaxies returned has been nearly
cut in half from the input sample and, unlike the LSSTErrorModel
degrader, is not equal to the number of input objects. Users should note
that with degraders that remove galaxies from the sample the size of the
output sample will not equal that of the input sample.

One more note: it is easy to use the QuantityCut degrader as a SNR cut
on the magnitudes. The magnitude equation is :math:`m = -2.5 \log(f)`.
Taking the derivative, we have

.. math::


   dm = \frac{2.5}{\ln(10)} \frac{df}{f} = \frac{2.5}{\ln(10)} \frac{1}{\mathrm{SNR}}.

So if you want to make a cut on galaxies above a certain SNR, you can
make a cut

.. math::


   dm < \frac{2.5}{\ln(10)} \frac{1}{\mathrm{SNR}}.

For example, an SNR cut on the i band would look like this:
``QuantityCut({"i_err": 2.5/np.log(10) * 1/SNR})``.

Degrader 3: InvRedshiftIncompleteness
-------------------------------------

Next, we will demonstrate the ``InvRedshiftIncompleteness`` degrader. It
applies a selection function, which keeps galaxies with probability
:math:`p_{\text{keep}}(z) = \min(1, \frac{z_p}{z})`, where :math:`z_p`
is the ‘’pivot’’ redshift. We’ll use :math:`z_p = 0.8`.

.. code:: ipython3

    inv_incomplete = InvRedshiftIncompleteness.make_stage(
        name="incompleteness", pivot_redshift=0.8
    )


.. code:: ipython3

    samples_incomplete_gold_w_errs = inv_incomplete(samples_gold_w_errs)



.. parsed-literal::

    Inserting handle into data store.  output_incompleteness: inprogress_output_incompleteness.pq, incompleteness


Let’s plot the redshift distributions of the samples we have generated
so far:

.. code:: ipython3

    fig, ax = plt.subplots(figsize=(5, 4), dpi=100)
    
    zmin = 0
    zmax = 2.5
    
    hist_settings = {
        "bins": 50,
        "range": (zmin, zmax),
        "density": True,
        "histtype": "step",
    }
    
    ax.hist(samples_truth()["redshift"], label="Truth", **hist_settings)
    ax.hist(samples_gold_w_errs()["redshift"], label="Gold", **hist_settings)
    ax.hist(
        samples_incomplete_gold_w_errs()["redshift"],
        label="Incomplete Gold",
        **hist_settings
    )
    ax.legend(title="Sample")
    ax.set(xlim=(zmin, zmax), xlabel="Redshift", ylabel="Galaxy density")
    plt.show()




.. image:: ../../../docs/rendered/creation_examples/degradation-demo_files/../../../docs/rendered/creation_examples/degradation-demo_30_0.png


You can see that the Gold sample has significantly fewer high-redshift
galaxies than the truth. This is because many of the high-redshift
galaxies have i > 25.3.

You can further see that the Incomplete Gold sample has even fewer
high-redshift galaxies. This is exactly what we expected from this
degrader.

Degrader 4: LineConfusion
-------------------------

``LineConfusion`` is a degrader that simulates spectroscopic errors
resulting from the confusion of different emission lines.

For this example, let’s use the degrader to simulate a scenario in which
which 2% of [OII] lines are mistaken as [OIII] lines, and 1% of [OIII]
lines are mistaken as [OII] lines. (note I do not know how realistic
this scenario is!)

.. code:: ipython3

    OII = 3727
    OIII = 5007
    
    lc_2p_0II_0III = LineConfusion.make_stage(
        name="lc_2p_0II_0III", true_wavelen=OII, wrong_wavelen=OIII, frac_wrong=0.02
    )
    lc_1p_0III_0II = LineConfusion.make_stage(
        name="lc_1p_0III_0II", true_wavelen=OIII, wrong_wavelen=OII, frac_wrong=0.01
    )


.. code:: ipython3

    samples_conf_inc_gold_w_errs = lc_1p_0III_0II(
        lc_2p_0II_0III(samples_incomplete_gold_w_errs)
    )



.. parsed-literal::

    Inserting handle into data store.  output_lc_2p_0II_0III: inprogress_output_lc_2p_0II_0III.pq, lc_2p_0II_0III
    Inserting handle into data store.  output_lc_1p_0III_0II: inprogress_output_lc_1p_0III_0II.pq, lc_1p_0III_0II


Let’s plot the redshift distributions one more time

.. code:: ipython3

    fig, ax = plt.subplots(figsize=(5, 4), dpi=100)
    
    zmin = 0
    zmax = 2.5
    
    hist_settings = {
        "bins": 50,
        "range": (zmin, zmax),
        "density": True,
        "histtype": "step",
    }
    
    ax.hist(samples_truth()["redshift"], label="Truth", **hist_settings)
    ax.hist(samples_gold_w_errs()["redshift"], label="Gold", **hist_settings)
    ax.hist(
        samples_incomplete_gold_w_errs()["redshift"],
        label="Incomplete Gold",
        **hist_settings
    )
    ax.hist(
        samples_conf_inc_gold_w_errs()["redshift"],
        label="Confused Incomplete Gold",
        **hist_settings
    )
    ax.legend(title="Sample")
    ax.set(xlim=(zmin, zmax), xlabel="Redshift", ylabel="Galaxy density")
    plt.show()




.. image:: ../../../docs/rendered/creation_examples/degradation-demo_files/../../../docs/rendered/creation_examples/degradation-demo_36_0.png


You can see that the redshift distribution of this new sample is
essentially identical to the Incomplete Gold sample, with small
perturbations that result from the line confusion.

However the real impact of this degrader isn’t on the redshift
distribution, but rather that it introduces erroneous spec-z’s into the
photo-z training sets! To see the impact of this effect, let’s plot the
true spec-z’s as present in the Incomplete Gold sample, vs the spec-z’s
listed in the new sample with Oxygen Line Confusion.

.. code:: ipython3

    fig, ax = plt.subplots(figsize=(6, 6), dpi=85)
    
    ax.scatter(
        samples_incomplete_gold_w_errs()["redshift"],
        samples_conf_inc_gold_w_errs()["redshift"],
        marker=".",
        s=1,
    )
    
    ax.set(
        xlim=(0, 2.5),
        ylim=(0, 2.5),
        xlabel="True spec-z (in Incomplete Gold sample)",
        ylabel="Spec-z listed in the Confused sample",
    )
    plt.show()




.. image:: ../../../docs/rendered/creation_examples/degradation-demo_files/../../../docs/rendered/creation_examples/degradation-demo_38_0.png


Now we can clearly see the spec-z errors! The galaxies above the line
y=x are the [OII] -> [OIII] galaxies, while the ones below are the
[OIII] -> [OII] galaxies.


